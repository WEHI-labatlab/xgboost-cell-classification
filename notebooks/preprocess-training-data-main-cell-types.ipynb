{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess training data for main cell types\n",
    "This notebook is for preprocessing annotated data which has been exported from QuPath.\n",
    "The data will be exported for XGBoost training or any supervised machine learning method of choice.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "# change you working directory to the xgboost-cell-phenotype folder\n",
    "%cd /Users/yokote.k/Desktop/MIBI/xgboost_demonstration/xgboost-cell-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input output files/folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Give your batch a name. Eg. If it is one of many batches of NSCLC, it could be\n",
    "NSCLCcohort_batch1_main_cell_types\n",
    "\"\"\"\n",
    "\n",
    "batch_name = \"test_run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Where the preprocessed files should be stored. The folder will be created if it doesn't already exist\n",
    "\"\"\"\n",
    "\n",
    "output_folder = \"resources/data/output\"\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The raw data exported from QuPath to be preprocessed\n",
    "\"\"\"\n",
    "\n",
    "expression_mat_path = \"resources/data/raw/test_training_raw_data.csv\"\n",
    "expression_df = pd.read_csv(expression_mat_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding the cell types\n",
    "When we train a machine learning model, the labels cannot be of type \"string\". For those new to coding, a string is a series of characters (can be alpha numeric, or special characters like .,!? etc) which are surrounded by quotation marks. The string data type is used to store names of things eg. the cell type of a particular cell. However, a machine learning program cannot really deal with strings, so instead what we need to do is to make an encoding or a mapping for each cell type to an integer. \n",
    "\n",
    "eg.   \n",
    "Other       -> 0  \n",
    "Epithelial  -> 1    \n",
    "Stromal     -> 2, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Preprocess the cell type column\n",
    "\"\"\"\n",
    "\n",
    "# cell types which you want to remove. By remove, the cell type will be changed\n",
    "# to what ever you set to the variable change_to\n",
    "cell_types_to_remove = [\"Immune cells\"]\n",
    "change_to = \"Other\"\n",
    "\n",
    "# Check that all the cell types are there\n",
    "# remove the Edited prefix which may have occured from the qupath script\n",
    "expression_df.loc[:, \"Class\"] = expression_df.loc[:, \"Class\"].str.replace(\"Edited: \", \"\")\n",
    "expression_df.loc[:, \"Name\"] = expression_df.loc[:, \"Name\"].str.replace(\"Edited: \", \"\")\n",
    "\n",
    "expression_df.loc[:, \"Class\"] = expression_df.loc[:, \"Class\"].str.replace(\"Immune cells: \", \"\")\n",
    "expression_df.loc[:, \"Name\"] = expression_df.loc[:, \"Name\"].str.replace(\"Immune cells: \", \"\")\n",
    "\n",
    "expression_df.loc[:, \"Class\"] = expression_df.loc[:, \"Class\"].replace(cell_types_to_remove, change_to)\n",
    "expression_df.loc[:, \"Name\"] = expression_df.loc[:, \"Name\"].replace(cell_types_to_remove, change_to)\n",
    "\n",
    "cell_types = expression_df.loc[:, \"Class\"].unique()\n",
    "cell_types = sorted(cell_types)\n",
    "\n",
    "\"\"\"\n",
    "If there are cell types which you want to remove that has been printed out, add them to the cell_types_to_remove. \n",
    "\"\"\"\n",
    "print(\"Defined cell types:\\n\", cell_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder for converting your labels\n",
    "encoder = {cell_types[i]:i for i in range(len(cell_types))}\n",
    "\n",
    "# decoder for decoding the results of the model. Save somewhere safe. \n",
    "decoder = {i:cell_types[i] for i in range(len(cell_types))}\n",
    "\n",
    "with open(os.path.join(output_folder, \"decoder.json\"), \"w\") as json_file:\n",
    "    json.dump(decoder, json_file, indent=4)\n",
    "\n",
    "print(\"Encoding:\", encoder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Save the labels as a separate csv file. The labels will be encoded with the above encoding\n",
    "\"\"\"\n",
    "filename = os.path.join(output_folder, \"{}_cell_type_labels.csv\".format(batch_name))\n",
    "labels = expression_df.loc[:, [\"Name\"]]\n",
    "labels = labels.replace({\"Name\" : encoder})\n",
    "labels.to_csv(filename, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the image, coordinate columns and any additional meta-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If for some reason, the centroid measurements are done in pixels and not µm, this will convert the pixel values to microns. \n",
    "\n",
    "The pixel_size variable is the microns/pixel. This information should be available somewhere idk. \n",
    "\"\"\"\n",
    "pixel_size = 0.3906\n",
    "\n",
    "for dim in [\"X\", \"Y\"]:\n",
    "    try:\n",
    "        null_arr = expression_df.loc[:, \"Centroid {} µm\".format(dim)].isnull()\n",
    "        if null_arr.any() != False:\n",
    "            expression_df.loc[null_arr.values, \"Centroid {} µm\".format(dim)] = expression_df.loc[null_arr.values, \"Centroid {} px\".format(dim)] * pixel_size\n",
    "            expression_df.drop([\"Centroid {} px\".format(dim)], axis=1)\n",
    "    except:\n",
    "        expression_df.loc[:, \"Centroid {} µm\".format(dim)] = expression_df.loc[:, \"Centroid {} px\".format(dim)] * pixel_size\n",
    "        expression_df = expression_df.drop([\"Centroid {} px\".format(dim)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Additional meta-data you want to keep. Eg. If you have a column indicating whether the cell is in tumour or not... \n",
    "\"\"\"\n",
    "additional_meta_data = []\n",
    "\n",
    "image_coord_cols = [\"Image\", \"Centroid X µm\", \"Centroid Y µm\"] + additional_meta_data\n",
    "image_coord_df = expression_df.loc[:, image_coord_cols]\n",
    "\n",
    "\"\"\"\n",
    "Save the image and coordinate columns. This is for when we want to import the results back into qupath\n",
    "\"\"\"\n",
    "image_coord_file_name = os.path.join(output_folder, \"{}_images.csv\".format(batch_name))\n",
    "image_coord_df.to_csv(image_coord_file_name, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The frequency of each cell type\n",
    "When training a machine learning model, one must consider the 'balance' of the data. If one or more cell types dominate the data-set, if the model performs well on the majority cell type, the accuracy will be high but will be a garbage model for the less frequent cell types. For this reason, it may be worth considering adding more of the rarer subtypes to try and compensate for this imbalance.   \n",
    "\n",
    "For the around 50,000 cells we annotated for the NSCLC cohort, at the very minimum, we had at least 200 annotations for each sub-type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_df.loc[:, \"Class\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the numerical measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_expression_df = expression_df.copy()\n",
    "\n",
    "\"\"\"\n",
    "Remove unnecessary prefixes and underscores. \n",
    "\"\"\"\n",
    "preprocessed_expression_df.columns = preprocessed_expression_df.columns.str.replace(\"Target:\", \"\")\n",
    "preprocessed_expression_df.columns = preprocessed_expression_df.columns.str.replace(\"_\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Collects all of the markers in this cohort\n",
    "\"\"\"\n",
    "# markers to include\n",
    "markers = [col.replace(\": Cell: Mean\", \"\") for col in preprocessed_expression_df.columns if \"Cell: Mean\" in col]\n",
    "print(markers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define any markers you want to remove from the phenotyping. \n",
    "\n",
    "In this step, markers which do not help in determining the cell type should be removed. For example, dsDNA will not help in determining\n",
    "cell types. \n",
    "\n",
    "Any markers where the staining did not work should also be removed.\n",
    "\"\"\"\n",
    "excluded_markers = [\"dsDNA\", \"Beta-Tubulin\", \"CD39\"]\n",
    "\n",
    "markers = [marker for marker in markers if marker not in excluded_markers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Keep only the columns with the markers you want to keep.\n",
    "\"\"\"\n",
    "markers_ = [s + \": \" for s  in markers]\n",
    "measurement_columns = [col for col in preprocessed_expression_df.columns if any(map(col.__contains__, markers_))]\n",
    "preprocessed_expression_df = preprocessed_expression_df.loc[:, measurement_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Due to the segmentation, some cells will not have a cytoplasm compartment. That is because the nuclei boundary and the cell boundary\n",
    "are the same pixels. This usually occurs in densely packed tumours where the nuclei and cell boundary merge. \n",
    "\n",
    "Because of this, some cells will have missing values in the cell cytoplasm measurements. We will therefore, instead of imputing the\n",
    "missing values with a 0, we will use the membrane measurement. This is a more representative way to impute the missing measurements. \n",
    "\"\"\"\n",
    "\n",
    "for col in preprocessed_expression_df.columns:\n",
    "    null_arr = preprocessed_expression_df.loc[:, col].isnull()\n",
    "    if null_arr.values.any():\n",
    "        if \"Cytoplasm\" in col: \n",
    "            new_col = col.replace(\"Cytoplasm\", \"Membrane\", 1)\n",
    "            preprocessed_expression_df.loc[null_arr.values, col] = preprocessed_expression_df.loc[null_arr.values, new_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check which columns still have NA values. This will be an issue with the measurement names across different images, and cohorts. \n",
    "If the problem is due to different measurement names across different images, this can be fixed by changing the names for the columns\n",
    "in the images where this is a problem. \n",
    "\n",
    "Some things to check:\n",
    "* Do all of my images have the same channel names on QuPath?\n",
    "* Did I change the channel names before or after the segmentation? \n",
    "    * If after, the measurements would have been created using the previous channel names.\n",
    "    * You can either change the names of the columns (best option) or if the channel names were\n",
    "      completely different and you don't know which corresponds to which, you should re run the segmentation\n",
    "      using the new channel names. \n",
    "\"\"\"\n",
    "print(preprocessed_expression_df.columns[preprocessed_expression_df.isna().any()].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If you believe that some compartments should not be considered during the phenotyping, remove them here\n",
    "\"\"\"\n",
    "compartments = []\n",
    "compartments_cols_to_remove = [col for col in preprocessed_expression_df.columns if any(map(col.__contains__, compartments))]\n",
    "preprocessed_expression_df = preprocessed_expression_df.drop(columns=compartments_cols_to_remove)\n",
    "\n",
    "\"\"\"\n",
    "If you believe that some statistics should not be considered during the phenotyping, remove them here\n",
    "\"\"\"\n",
    "statistics = []\n",
    "statistics_cols_to_remove = [col for col in preprocessed_expression_df.columns if any(map(col.__contains__, statistics))]\n",
    "preprocessed_expression_df = preprocessed_expression_df.drop(columns=statistics_cols_to_remove)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the preprocessed measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Save the input preprocessed data\n",
    "\"\"\"\n",
    "preprocessed_expression_df_path = os.path.join(output_folder,  \"{}_preprocessed_input_data.csv\".format(batch_name))\n",
    "preprocessed_expression_df.to_csv(preprocessed_expression_df_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('xgboost-cell-classification')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76ab5027b75e2f564af743d92b322b9cd59fa3e08912bbe69d218e42f22de9ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
